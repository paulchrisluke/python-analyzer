#!/usr/bin/env python3
"""
Test script for ETL pipeline validation.

This script runs basic tests to ensure the ETL pipeline is working correctly
before running the full pipeline on production data.
"""

import sys
import logging
import json
import pandas as pd
from pathlib import Path
from collections import defaultdict

# Add the parent directory to the Python path so etl_pipeline can be imported
sys.path.insert(0, str(Path(__file__).parent))

from etl_pipeline.utils.logging_config import setup_logging
from etl_pipeline.utils.file_utils import FileUtils
from etl_pipeline.pipeline_runner import ETLPipeline

def test_configuration_loading():
    """Test that configuration files can be loaded."""
    print("Testing configuration loading...")
    
    try:
        # Test YAML loading
        config_dir = Path(__file__).parent / "etl_pipeline" / "config"
        
        data_sources = FileUtils.load_yaml(str(config_dir / "data_sources.yaml"))
        business_rules = FileUtils.load_yaml(str(config_dir / "business_rules.yaml"))
        schemas = FileUtils.load_yaml(str(config_dir / "schemas.yaml"))
        
        print("‚úÖ Configuration files loaded successfully")
        print(f"   - Data sources: {len(data_sources.get('data_sources', {}))} configured")
        print(f"   - Business rules: {len(business_rules)} sections")
        print(f"   - Schemas: {len(schemas.get('schemas', {}))} defined")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Configuration loading failed: {str(e)}")
        return False

def test_data_source_validation():
    """Test that data source files exist."""
    print("\nTesting data source validation...")
    
    try:
        config_dir = Path(__file__).parent / "etl_pipeline" / "config"
        data_sources = FileUtils.load_yaml(str(config_dir / "data_sources.yaml"))
        
        # Check main sales file
        sales_config = data_sources.get('data_sources', {}).get('sales', {})
        if sales_config:
            sales_path = Path(sales_config['path'])
            if sales_path.exists():
                print(f"‚úÖ Main sales file found: {sales_path}")
            else:
                print(f"‚ùå Main sales file not found: {sales_path}")
                return False
        
        # Check financial data directories
        financial_configs = [
            'financial_pnl_2023',
            'financial_pnl_2024',
            'financial_balance_sheets',
            'financial_general_ledger',
            'financial_cogs'
        ]
        
        for config_name in financial_configs:
            config = data_sources.get('data_sources', {}).get(config_name, {})
            if config:
                path = Path(config['path'])
                if path.exists():
                    print(f"‚úÖ {config_name} directory found: {path}")
                else:
                    print(f"‚ö†Ô∏è  {config_name} directory not found: {path}")
        
        # Check equipment files
        equipment_config = data_sources.get('data_sources', {}).get('equipment_quotes', {})
        if equipment_config:
            base_path = Path(equipment_config['path'])
            if base_path.exists():
                pdf_files = FileUtils.find_files(str(base_path), "M1566*.pdf")
                if pdf_files:
                    print(f"‚úÖ Equipment PDF files found: {len(pdf_files)} files")
                else:
                    print(f"‚ö†Ô∏è  No equipment PDF files found in: {base_path}")
            else:
                print(f"‚ö†Ô∏è  Equipment base path not found: {base_path}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Data source validation failed: {str(e)}")
        return False

def test_pipeline_initialization():
    """Test that the pipeline can be initialized."""
    print("\nTesting pipeline initialization...")
    
    try:
        # Setup logging
        logger = setup_logging(log_level=logging.INFO)
        
        # Initialize pipeline
        pipeline = ETLPipeline()
        
        if pipeline.initialize():
            print("‚úÖ Pipeline initialized successfully")
            print(f"   - Extractors: {len(pipeline.extractors)}")
            print(f"   - Transformers: {len(pipeline.transformers)}")
            print(f"   - Loaders: {len(pipeline.loaders)}")
            return True
        else:
            print("‚ùå Pipeline initialization failed")
            return False
            
    except Exception as e:
        print(f"‚ùå Pipeline initialization test failed: {str(e)}")
        return False

def test_directory_structure():
    """Test that required directories exist or can be created."""
    print("\nTesting directory structure...")
    
    try:
        base_dir = Path(__file__).parent
        
        # Check required directories
        required_dirs = [
            "etl_pipeline",
            "etl_pipeline/config",
            "etl_pipeline/extract",
            "etl_pipeline/transform",
            "etl_pipeline/load",
            "etl_pipeline/utils"
        ]
        
        for dir_path in required_dirs:
            full_path = base_dir / dir_path
            if full_path.exists():
                print(f"‚úÖ Directory exists: {dir_path}")
            else:
                print(f"‚ùå Directory missing: {dir_path}")
                return False
        
        # Test data directories can be created
        data_dirs = ["data", "data/raw", "data/normalized", "data/final", "reports", "logs"]
        
        for dir_path in data_dirs:
            full_path = base_dir / dir_path
            full_path.mkdir(parents=True, exist_ok=True)
            print(f"‚úÖ Data directory ready: {dir_path}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Directory structure test failed: {str(e)}")
        return False

def test_data_completeness():
    """Test that all data is extracted and processed without loss."""
    print("\nTesting data completeness...")
    
    try:
        base_dir = Path(__file__).parent
        raw_data_path = base_dir / "data" / "raw"
        normalized_data_path = base_dir / "data" / "normalized"
        final_data_path = base_dir / "data" / "final"
        
        # Load data if it exists
        raw_data = {}
        normalized_data = {}
        final_data = {}
        
        if raw_data_path.exists():
            for file_path in raw_data_path.glob("*.json"):
                with open(file_path, 'r') as f:
                    raw_data[file_path.stem] = json.load(f)
        
        if normalized_data_path.exists():
            for file_path in normalized_data_path.glob("*.json"):
                with open(file_path, 'r') as f:
                    normalized_data[file_path.stem] = json.load(f)
        
        if final_data_path.exists():
            for file_path in final_data_path.glob("*.json"):
                with open(file_path, 'r') as f:
                    final_data[file_path.stem] = json.load(f)
        
        # Test raw data completeness
        if raw_data:
            print("‚úÖ Raw data files found:")
            for data_type, data in raw_data.items():
                if isinstance(data, dict):
                    record_count = len(data)
                    print(f"   - {data_type}: {record_count} records")
                else:
                    print(f"   - {data_type}: {type(data).__name__}")
        else:
            print("‚ö†Ô∏è  No raw data found - run pipeline first")
            return True  # Don't fail if no data yet
        
        # Test normalized data completeness
        if normalized_data:
            print("‚úÖ Normalized data files found:")
            for data_type, data in normalized_data.items():
                if isinstance(data, dict):
                    record_count = len(data)
                    print(f"   - {data_type}: {record_count} records")
                else:
                    print(f"   - {data_type}: {type(data).__name__}")
        else:
            print("‚ö†Ô∏è  No normalized data found - run pipeline first")
            return True  # Don't fail if no data yet
        
        # Test final data completeness
        if final_data:
            print("‚úÖ Final data files found:")
            for data_type, data in final_data.items():
                if isinstance(data, dict):
                    print(f"   - {data_type}: {len(data)} sections")
                else:
                    print(f"   - {data_type}: {type(data).__name__}")
        else:
            print("‚ö†Ô∏è  No final data found - run pipeline first")
            return True  # Don't fail if no data yet
        
        return True
        
    except Exception as e:
        print(f"‚ùå Data completeness test failed: {str(e)}")
        return False

def test_financial_data_integrity():
    """Test that all financial data columns and rows are preserved."""
    print("\nTesting financial data integrity...")
    
    try:
        base_dir = Path(__file__).parent
        raw_data_path = base_dir / "data" / "raw" / "financial_raw.json"
        
        if not raw_data_path.exists():
            print("‚ö†Ô∏è  No financial raw data found - run pipeline first")
            return True
        
        with open(raw_data_path, 'r') as f:
            financial_data = json.load(f)
        
        # Test P&L data completeness
        if 'profit_loss' in financial_data:
            pnl_data = financial_data['profit_loss']
            print(f"‚úÖ P&L statements found: {len(pnl_data)}")
            
            total_rows = 0
            total_columns = 0
            
            for pnl_key, pnl_info in pnl_data.items():
                if isinstance(pnl_info, dict) and 'data' in pnl_info:
                    df = pd.DataFrame(pnl_info['data'])
                    rows = len(df)
                    cols = len(df.columns)
                    total_rows += rows
                    total_columns += cols
                    
                    # Check for essential columns
                    essential_columns = ['Unnamed: 0', 'TOTAL']
                    for col in essential_columns:
                        if col not in df.columns:
                            print(f"‚ùå Missing essential column '{col}' in {pnl_key}")
                            return False
                    
                    # Check that no columns are completely empty
                    for col in df.columns:
                        non_null_count = df[col].notna().sum()
                        if non_null_count == 0:
                            print(f"‚ùå Column '{col}' in {pnl_key} is completely empty")
                            return False
                    
                    print(f"   - {pnl_key}: {rows} rows, {cols} columns")
            
            print(f"‚úÖ Total P&L data: {total_rows} rows, {total_columns} columns")
        
        # Test balance sheet data
        if 'balance_sheet' in financial_data:
            bs_data = financial_data['balance_sheet']
            print(f"‚úÖ Balance sheets found: {len(bs_data)}")
            
            for bs_key, bs_info in bs_data.items():
                if isinstance(bs_info, dict) and 'data' in bs_info:
                    df = pd.DataFrame(bs_info['data'])
                    print(f"   - {bs_key}: {len(df)} rows, {len(df.columns)} columns")
        
        # Test general ledger data
        if 'general_ledger' in financial_data:
            gl_data = financial_data['general_ledger']
            print(f"‚úÖ General ledger files found: {len(gl_data)}")
            
            for gl_key, gl_info in gl_data.items():
                if isinstance(gl_info, dict) and 'data' in gl_info:
                    df = pd.DataFrame(gl_info['data'])
                    print(f"   - {gl_key}: {len(df)} rows, {len(df.columns)} columns")
        
        # Test COGS data
        if 'cogs' in financial_data:
            cogs_data = financial_data['cogs']
            print(f"‚úÖ COGS files found: {len(cogs_data)}")
            
            for cogs_key, cogs_info in cogs_data.items():
                if isinstance(cogs_info, dict) and 'data' in cogs_info:
                    df = pd.DataFrame(cogs_info['data'])
                    print(f"   - {cogs_key}: {len(df)} rows, {len(df.columns)} columns")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Financial data integrity test failed: {str(e)}")
        return False

def test_sales_data_integrity():
    """Test that all sales data is preserved."""
    print("\nTesting sales data integrity...")
    
    try:
        base_dir = Path(__file__).parent
        raw_data_path = base_dir / "data" / "raw" / "sales_raw.json"
        
        if not raw_data_path.exists():
            print("‚ö†Ô∏è  No sales raw data found - run pipeline first")
            return True
        
        with open(raw_data_path, 'r') as f:
            sales_data = json.load(f)
        
        if 'main_sales' in sales_data and 'data' in sales_data['main_sales']:
            df = pd.DataFrame(sales_data['main_sales']['data'])
            print(f"‚úÖ Sales data: {len(df)} rows, {len(df.columns)} columns")
            
            # Check for essential sales columns
            expected_columns = ['Date', 'Amount', 'Customer', 'Service']
            found_columns = []
            
            for col in df.columns:
                if any(expected in col for expected in expected_columns):
                    found_columns.append(col)
            
            if found_columns:
                print(f"‚úÖ Found expected sales columns: {found_columns}")
            else:
                print("‚ö†Ô∏è  No expected sales columns found")
            
            # Check that no columns are completely empty
            empty_columns = []
            for col in df.columns:
                non_null_count = df[col].notna().sum()
                if non_null_count == 0:
                    empty_columns.append(col)
            
            if empty_columns:
                print(f"‚ö†Ô∏è  Empty columns found: {empty_columns}")
            else:
                print("‚úÖ No empty columns found")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Sales data integrity test failed: {str(e)}")
        return False

def test_business_metrics_completeness():
    """Test that all business metrics are calculated."""
    print("\nTesting business metrics completeness...")
    
    try:
        base_dir = Path(__file__).parent
        final_data_path = base_dir / "data" / "final" / "business_sale_data.json"
        
        if not final_data_path.exists():
            print("‚ö†Ô∏è  No business sale data found - run pipeline first")
            return True
        
        with open(final_data_path, 'r') as f:
            business_data = json.load(f)
        
        # Check that all expected metrics are calculated
        expected_metrics = ['revenue', 'ebitda', 'profitability', 'equipment']
        for metric in expected_metrics:
            if metric in business_data:
                print(f"‚úÖ {metric} metrics calculated")
            else:
                print(f"‚ùå Missing {metric} metrics")
                return False
        
        # Check revenue metrics
        if 'revenue' in business_data:
            revenue = business_data['revenue']
            required_revenue_fields = ['total_revenue', 'monthly_average', 'annual_projection']
            for field in required_revenue_fields:
                if field in revenue:
                    value = revenue[field]
                    if value > 0:
                        print(f"‚úÖ {field}: ${value:,.2f}")
                    else:
                        print(f"‚ùå {field} is zero or negative: {value}")
                        return False
                else:
                    print(f"‚ùå Missing {field} in revenue metrics")
                    return False
        
        # Check EBITDA metrics
        if 'ebitda' in business_data:
            ebitda = business_data['ebitda']
            required_ebitda_fields = ['estimated_annual', 'margin_percentage']
            for field in required_ebitda_fields:
                if field in ebitda:
                    value = ebitda[field]
                    if value > 0:
                        print(f"‚úÖ {field}: {value:,.2f}")
                    else:
                        print(f"‚ùå {field} is zero or negative: {value}")
                        return False
                else:
                    print(f"‚ùå Missing {field} in EBITDA metrics")
                    return False
        
        return True
        
    except Exception as e:
        print(f"‚ùå Business metrics completeness test failed: {str(e)}")
        return False

def test_data_coverage_analysis():
    """Test that data coverage analysis is complete."""
    print("\nTesting data coverage analysis...")
    
    try:
        base_dir = Path(__file__).parent
        coverage_data_path = base_dir / "data" / "final" / "due_diligence_coverage.json"
        
        if not coverage_data_path.exists():
            print("‚ö†Ô∏è  No coverage data found - run pipeline first")
            return True
        
        with open(coverage_data_path, 'r') as f:
            coverage_data = json.load(f)
        
        # Check that all expected coverage areas are analyzed
        expected_coverage = ['sales', 'financial', 'equipment']
        for coverage_type in expected_coverage:
            if coverage_type in coverage_data:
                coverage_info = coverage_data[coverage_type]
                if isinstance(coverage_info, dict):
                    coverage_pct = coverage_info.get('coverage_percentage', 0)
                    status = coverage_info.get('status', 'unknown')
                    print(f"‚úÖ {coverage_type}: {coverage_pct}% coverage, status: {status}")
                else:
                    print(f"‚úÖ {coverage_type}: {coverage_info}")
            else:
                print(f"‚ùå Missing coverage analysis for {coverage_type}")
                return False
        
        return True
        
    except Exception as e:
        print(f"‚ùå Data coverage analysis test failed: {str(e)}")
        return False

def main():
    """Run all tests."""
    print("="*60)
    print("ETL PIPELINE COMPREHENSIVE VALIDATION TESTS")
    print("="*60)
    print("Testing all columns, rows, and data completeness...")
    
    # Basic pipeline tests
    basic_tests = [
        ("Configuration Loading", test_configuration_loading),
        ("Data Source Validation", test_data_source_validation),
        ("Directory Structure", test_directory_structure),
        ("Pipeline Initialization", test_pipeline_initialization)
    ]
    
    # Data completeness tests (run after pipeline has been executed)
    completeness_tests = [
        ("Data Completeness", test_data_completeness),
        ("Financial Data Integrity", test_financial_data_integrity),
        ("Sales Data Integrity", test_sales_data_integrity),
        ("Business Metrics Completeness", test_business_metrics_completeness),
        ("Data Coverage Analysis", test_data_coverage_analysis)
    ]
    
    all_tests = basic_tests + completeness_tests
    
    # Store test results to avoid duplicate execution
    test_results = []
    
    print(f"\n{'='*20} BASIC PIPELINE TESTS {'='*20}")
    for test_name, test_func in basic_tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        result = test_func()
        test_results.append((test_name, result))
        if result:
            print(f"‚úÖ {test_name} PASSED")
        else:
            print(f"‚ùå {test_name} FAILED")
    
    print(f"\n{'='*20} DATA COMPLETENESS TESTS {'='*20}")
    for test_name, test_func in completeness_tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        result = test_func()
        test_results.append((test_name, result))
        if result:
            print(f"‚úÖ {test_name} PASSED")
        else:
            print(f"‚ùå {test_name} FAILED")
    
    # Count passed tests from stored results
    passed = sum(1 for _, result in test_results if result)
    total = len(test_results)
    
    print("\n" + "="*60)
    print("COMPREHENSIVE TEST SUMMARY")
    print("="*60)
    print(f"Tests Passed: {passed}/{total}")
    print(f"Success Rate: {(passed/total*100):.1f}%")
    
    # Categorize results from stored test results
    basic_passed = sum(1 for test_name, result in test_results[:len(basic_tests)] if result)
    completeness_passed = sum(1 for test_name, result in test_results[len(basic_tests):] if result)
    
    print(f"\nBasic Pipeline Tests: {basic_passed}/{len(basic_tests)} passed")
    print(f"Data Completeness Tests: {completeness_passed}/{len(completeness_tests)} passed")
    
    if passed == total:
        print("\nüéâ ALL TESTS PASSED - ETL Pipeline is complete and accurate!")
        print("\n‚úÖ All columns and rows are accounted for")
        print("‚úÖ No data is being skipped or lost")
        print("‚úÖ All business metrics are calculated correctly")
        print("\nNext steps:")
        print("1. Pipeline is ready for production use")
        print("2. Data integrity is verified")
        print("3. All CSV data is properly processed")
        return 0
    elif basic_passed == len(basic_tests):
        print("\n‚úÖ BASIC PIPELINE TESTS PASSED")
        if completeness_passed < len(completeness_tests):
            print("‚ö†Ô∏è  Some data completeness tests failed - run pipeline first:")
            print("   python run_pipeline.py")
            print("   Then run tests again to verify data completeness")
        return 0
    else:
        print("\n‚ùå BASIC PIPELINE TESTS FAILED")
        print("Please fix configuration and setup issues before running pipeline")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
