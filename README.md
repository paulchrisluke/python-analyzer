# ETL Pipeline for Business Analysis

A comprehensive Extract, Transform, Load (ETL) pipeline for business analysis and valuation, with specialized features for due diligence data management.

## ğŸš€ Quick Start

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Run the pipeline**:
   ```bash
   python run_pipeline.py
   ```

3. **Deploy to website**:
   ```bash
   ./deploy_website.sh
   ```

## ğŸ“ Repository Structure

```
â”œâ”€â”€ etl_pipeline/                # Core ETL pipeline modules
â”‚   â”œâ”€â”€ config/                  # Configuration files
â”‚   â”œâ”€â”€ extract/                 # Data extraction modules
â”‚   â”œâ”€â”€ transform/               # Data transformation modules
â”‚   â”œâ”€â”€ load/                    # Data loading modules
â”‚   â”œâ”€â”€ utils/                   # Utility functions
â”‚   â””â”€â”€ pipeline_runner.py       # Internal pipeline runner
â”œâ”€â”€ data/                        # Data storage and processing
â”‚   â”œâ”€â”€ final/                   # Processed output data
â”‚   â”œâ”€â”€ normalized/              # Normalized data files
â”‚   â”œâ”€â”€ raw/                     # Raw input data
â”‚   â””â”€â”€ pipeline_summary.json    # Pipeline execution summary
â”œâ”€â”€ reports/                     # Generated analysis reports
â”œâ”€â”€ logs/                        # Pipeline execution logs
â”œâ”€â”€ tests/                       # Test suite
â”œâ”€â”€ examples/                    # Example scripts and usage
â”œâ”€â”€ docs/                        # Documentation
â”œâ”€â”€ website/                     # Cloudflare Pages website
â”œâ”€â”€ run_pipeline.py              # Main pipeline runner
â”œâ”€â”€ deploy_to_website.py         # Website deployment script
â”œâ”€â”€ deploy_website.sh            # Website deployment shell script
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ ETL_PIPELINE_TECHNICAL_DOCUMENTATION.md  # Technical documentation
â””â”€â”€ README.md                    # This file
```

## âœ¨ Key Features

- **Multi-Source Data Processing**: CSV files, PDF documents, financial statements
- **Configurable Business Rules**: Location filtering, date ranges, financial metrics
- **Real Financial Calculations**: EBITDA, ROI, revenue projections
- **Data Coverage Analysis**: Due diligence completeness assessment
- **Website Integration**: Automatic deployment to Cloudflare Pages

## ğŸ”§ Configuration

Configure business rules and data sources in `etl_pipeline/config/`:

- `business_rules.yaml` - Business logic and analysis parameters
- `data_sources.yaml` - Data source paths and processing options

## ğŸ“Š Output

The pipeline generates:
- `business_sale_data.json` - Main business metrics
- `due_diligence_coverage.json` - Data coverage analysis
- `equipment_analysis.json` - Equipment valuation

## ğŸ§ª Testing

```bash
python -m pytest tests/
```

## ğŸ”’ Privacy & Security

- **Anonymized Data Only**: All business data in this repository is anonymized/synthetic for demonstration purposes
- **Production Pipeline**: Real business data is processed only in a separate, secured production pipeline with proper safeguards
- **Comprehensive Git Ignore**: Prevents accidental commits of sensitive data

## ğŸ“ License

MIT License - see LICENSE file for details.

---

**Note**: This system demonstrates ETL pipeline functionality using anonymized/synthetic data. Real business data is processed only in a separate, secured production pipeline with proper data handling and privacy controls.